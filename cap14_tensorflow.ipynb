{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Python para Ciência de Dados</font>\n",
    "# <font color='blue'>Capítulo 14</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python usada neste Jupyter Notebook: 3.10.12\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python usada neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/igor/.local/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
      "Collecting numpy<2.0.0,>=1.23.5\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in /home/igor/.local/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.25.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.28.1-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.9/186.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /home/igor/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.2.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/igor/.local/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/igor/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, requests-oauthlib, pyasn1, protobuf, numpy, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, pyasn1-modules, opt-einsum, ml-dtypes, h5py, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.4\n",
      "    Uninstalling numpy-1.23.4:\n",
      "      Successfully uninstalled numpy-1.23.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.9.3 requires numpy<1.26.0,>=1.18.5, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.3 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.28.1 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.62.0 h5py-3.10.0 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 numpy-1.26.4 opt-einsum-3.3.0 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Instalando o tensorflow\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 13:37:22.362246: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 13:37:22.362273: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 13:37:22.363109: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 13:37:22.368399: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-05 13:37:23.084131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/igor/.local/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Importando a biblioteca\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a versão\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 17:48:51.559658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 17:48:51.559685: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 17:48:51.560589: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 17:48:51.566551: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 17:48:52.296576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/igor/.local/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 17:48:57.380208: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 17:49:05.708156: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2948 - accuracy: 0.9142\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1406 - accuracy: 0.9585\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1061 - accuracy: 0.9679\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0852 - accuracy: 0.9738\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0726 - accuracy: 0.9773\n",
      "313/313 [==============================] - 0s 833us/step - loss: 0.0768 - accuracy: 0.9766\n",
      "Test accuracy: 0.9765999913215637\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Carregar dados de treinamento e teste\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Definir o modelo\n",
    "model = models.Sequential([\n",
    " layers.Flatten(input_shape=(28, 28)),\n",
    " layers.Dense(128, activation='relu'),\n",
    " layers.Dropout(0.2),\n",
    " layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam',\n",
    " loss='sparse_categorical_crossentropy',\n",
    " metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# Avaliar o modelo\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando o TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 13:37:35.599830: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Criando um tensor\n",
    "hello = tf.constant('Hello, Python for DataScience!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Hello, Python for DataScience!', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Criar um tensor constante\n",
    "tensor_const = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "print(tensor_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3,) dtype=int32, numpy=array([5, 6, 7], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "# Criar um tensor variável\n",
    "tensor_var = tf.Variable([5, 6, 7])\n",
    "\n",
    "print(tensor_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Criar um tensor preenchido com zeros\n",
    "tensor_zeros = tf.zeros((3, 3))\n",
    "\n",
    "print(tensor_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Criar um tensor preenchido com uns\n",
    "tensor_ones = tf.ones((2, 2))\n",
    "\n",
    "print(tensor_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.6687336  -2.3767953  -0.5301165 ]\n",
      " [ 0.27705908 -0.9660335  -0.664342  ]\n",
      " [ 0.06038933  0.730116    0.49838436]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Criar um tensor com valores aleatórios de uma distribuição normal\n",
    "tensor_random_normal = tf.random.normal((3, 3))\n",
    "\n",
    "print(tensor_random_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operações Matemáticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adição de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Adição de tensores\n",
    "\n",
    "# criando constantes\n",
    "const_a = tf.constant(5)\n",
    "const_b = tf.constant(9)\n",
    "\n",
    "print(const_a)\n",
    "print(const_b)\n",
    "\n",
    "# Soma\n",
    "total = const_a + const_b\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A soma do node1 com o node2 é: tf.Tensor(14, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Criando nodes no grafo computacional\n",
    "node1 = tf.constant(5, dtype = tf.int32)\n",
    "node2 = tf.constant(9, dtype = tf.int32)\n",
    "node3 = tf.add(node1, node2)\n",
    " \n",
    "# Executa o grafo\n",
    "print(\"\\nA soma do node1 com o node2 é:\", node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtração de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensores\n",
    "tensor_a = tf.constant([[1, 2], [3, 4]])\n",
    "tensor_b = tf.constant([[5, 0], [7, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5 0]\n",
      " [7 9]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtração\n",
    "diff = tf.subtract(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subtração entre os 2 tensores é:  tf.Tensor(\n",
      "[[-4  2]\n",
      " [-4 -5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('\\nSubtração entre os 2 tensores é: ', diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensores\n",
    "node1 = tf.constant(21, dtype = tf.int32)\n",
    "node2 = tf.constant(7, dtype = tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão\n",
    "div = tf.math.truediv(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Divisão Entre os Tensores: \n",
      " tf.Tensor(3.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print('\\nDivisão Entre os Tensores: \\n', div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando tensores\n",
    "tensor_a = tf.constant([[5., 3.]])\n",
    "tensor_b = tf.constant([[4.],[8.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5. 3.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.]\n",
      " [8.]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicação\n",
    "# tf.math.multiply(X, Y) executa multiplicação element-wise \n",
    "# https://www.tensorflow.org/api_docs/python/tf/math/multiply\n",
    "prod = tf.math.multiply(tensor_a, tensor_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Produto Element-wise Entre os Tensores: \n",
      " tf.Tensor(\n",
      "[[20. 12.]\n",
      " [40. 24.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('\\nProduto Element-wise Entre os Tensores: \\n', prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando tensores\n",
    "tensor_a = tf.constant([[5., 3.]])\n",
    "tensor_b = tf.constant([[4.],[8.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[148.41316   20.085537]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor_exp_a = tf.exp(tensor_a)\n",
    "\n",
    "print(tensor_exp_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  54.59815]\n",
      " [2980.958  ]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor_exp_b = tf.exp(tensor_b)\n",
    "\n",
    "print(tensor_exp_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redução de Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Criando tensores\n",
    "tensor_c = tf.constant([[9., 1.]])\n",
    "\n",
    "# Redução de soma\n",
    "tensor_sum = tf.reduce_sum(tensor_)\n",
    "\n",
    "print(tensor_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Redução de média\n",
    "tensor_mean = tf.reduce_mean(tensor_c)\n",
    "\n",
    "print(tensor_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Álgebra Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[44.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Produto interno\n",
    "tensor_dot = tf.tensordot(tensor_a, tensor_b, axes=1)\n",
    "\n",
    "print(tensor_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5.]\n",
      " [3.]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Transposição de tensor\n",
    "\n",
    "# Matriz 1x2 virou 2x1\n",
    "tensor_transpose = tf.transpose(tensor_a)\n",
    "\n",
    "print(tensor_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4. 8.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Transposição de tensor\n",
    "\n",
    "# Matriz 2x1 virou 1x2\n",
    "tensor_transpose = tf.transpose(tensor_b)\n",
    "\n",
    "print(tensor_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.constant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 14:39:37.026867: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 14:39:37.026896: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 14:39:37.027727: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 14:39:37.033089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-05 14:39:37.778902: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/igor/.local/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-03-05 14:39:38.585911: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor constante a partir de um escalar\n",
    "tensor1 = tf.constant(5.0)\n",
    "\n",
    "# Criar um tensor constante a partir de uma lista\n",
    "tensor2 = tf.constant([1, 2, 3, 4, 5])\n",
    "\n",
    "# Criar um tensor constante a partir de uma matriz NumPy\n",
    "import numpy as np\n",
    "array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "tensor3 = tf.constant(array)\n",
    "\n",
    "# Especificar o tipo de dado e o nome do tensor\n",
    "tensor4 = tf.constant(3.14, dtype=tf.float32, name='pi')\n",
    "\n",
    "# Especificar a forma do tensor\n",
    "tensor5 = tf.constant(0, shape=(2, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor variável a partir de um escalar\n",
    "variable1 = tf.Variable(5.0)\n",
    "\n",
    "# Criar um tensor variável a partir de uma lista\n",
    "variable2 = tf.Variable([1, 2, 3, 4, 5])\n",
    "\n",
    "# Criar um tensor variável a partir de uma matriz NumPy\n",
    "import numpy as np\n",
    "array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "variable3 = tf.Variable(array)\n",
    "\n",
    "# Especificar o tipo de dado e o nome do tensor\n",
    "variable4 = tf.Variable(3.14, dtype=tf.float32, name='pi')\n",
    "\n",
    "# Especificar que o tensor não é treinável\n",
    "variable5 = tf.Variable(0, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor preenchido com zeros de forma (3, 3)\n",
    "tensor1 = tf.zeros((3, 3))\n",
    "\n",
    "# Criar um tensor preenchido com zeros de forma (2, 2, 2) e tipo de dado tf.int32\n",
    "tensor2 = tf.zeros((2, 2, 2), dtype=tf.int32)\n",
    "\n",
    "# Criar um tensor preenchido com zeros de forma (4,) e nome 'zeros_tensor'\n",
    "tensor3 = tf.zeros([4], name='zeros_tensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.ones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor preenchido com uns\n",
    "ones_tensor = tf.ones(shape=(2, 2))\n",
    "# Especificar o nome do tensor\n",
    "ones_named_tensor = tf.ones(shape=(2, 2), name='ones_tensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.fill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[7 7 7]\n",
      " [7 7 7]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor preenchido com o valor 7\n",
    "filled_tensor = tf.fill(dims=(2, 3), value=7)\n",
    "\n",
    "print(filled_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.763717    1.6245904   0.8401559 ]\n",
      " [ 0.02932856 -0.08718653  0.22539632]\n",
      " [ 0.7837219  -0.62873846 -1.4869293 ]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor com forma (3, 3) contendo valores amostrados de uma distribuição normal\n",
    "tensor = tf.random.normal(shape=(3, 3), mean=0.0, stddev=1.0)\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.random.uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.12028646 0.03995156 0.02232838]\n",
      " [0.00733566 0.5506784  0.58341694]\n",
      " [0.09539127 0.9294827  0.04922581]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor com forma (3, 3) contendo valores amostrados de uma distribuição uniforme no intervalo [0, 1]\n",
    "tensor = tf.random.uniform(shape=(3, 3))\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar dois tensores\n",
    "tensor1 = tf.constant([1, 2, 3])\n",
    "tensor2 = tf.constant([4, 5, 6])\n",
    "\n",
    "# Realizar a adição dos tensores\n",
    "result = tf.add(tensor1, tensor2)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.subtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3 -3 -3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar dois tensores\n",
    "tensor1 = tf.constant([1, 2, 3])\n",
    "tensor2 = tf.constant([4, 5, 6])\n",
    "\n",
    "# Realizar a subtração dos tensores\n",
    "result = tf.subtract(tensor1, tensor2)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.multiply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 10 18]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar dois tensores\n",
    "tensor1 = tf.constant([1, 2, 3])\n",
    "tensor2 = tf.constant([4, 5, 6])\n",
    "\n",
    "# Realizar a multiplicação dos tensores\n",
    "result = tf.multiply(tensor1, tensor2)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.divide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 4.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar dois tensores\n",
    "tensor1 = tf.constant([4, 6, 8])\n",
    "tensor2 = tf.constant([2, 3, 2])\n",
    "\n",
    "# Realizar a divisão dos tensores\n",
    "result = tf.divide(tensor1, tensor2)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.7182817  7.389056  20.085537 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([1.0, 2.0, 3.0])\n",
    "\n",
    "# Calcular a exponencial do tensor\n",
    "result = tf.exp(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.6931472 1.0986123]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([1.0, 2.0, 3.0])\n",
    "\n",
    "# Calcular o logaritmo natural do tensor\n",
    "result = tf.math.log(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([4.0, 9.0, 16.0])\n",
    "\n",
    "# Calcular a raiz quadrada do tensor\n",
    "result = tf.sqrt(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.sin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.000000e+00  1.000000e+00 -8.742278e-08]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([0.0, np.pi/2, np.pi])\n",
    "\n",
    "# Calcular o seno do tensor\n",
    "result = tf.sin(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.cos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.000000e+00 -4.371139e-08 -1.000000e+00]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([0.0, np.pi/2, np.pi])\n",
    "\n",
    "# Calcular o cosseno do tensor\n",
    "result = tf.cos(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reduce_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "# Calcular a soma do tensor\n",
    "result = tf.reduce_sum(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reduce_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "# Calcular a média do tensor\n",
    "result = tf.reduce_mean(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reduce_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "# Calcular o valor máximo do tensor\n",
    "result = tf.reduce_max(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reduce_min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "# Calcular o valor mínimo do tensor\n",
    "result = tf.reduce_min(tensor)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.linalg.det()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar uma matriz\n",
    "matrix = tf.constant([[1, 2], [3, 4]], dtype=tf.float64)\n",
    "\n",
    "# Calcular o determinante da matriz\n",
    "determinant = tf.linalg.det(matrix)\n",
    "\n",
    "print(determinant.numpy())  # Convertendo para NumPy array para visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.linalg.inv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar uma matriz\n",
    "matrix = tf.constant([[1, 2], [3, 4]], dtype=tf.float64)\n",
    "\n",
    "# Calcular a inversa da matriz\n",
    "inverse = tf.linalg.inv(matrix)\n",
    "\n",
    "print(inverse.numpy())  # Convertendo para NumPy array para visualização\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.matmul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20 28]\n",
      " [52 76]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar dois tensores\n",
    "a = tf.constant([[1, 3], [5, 7]])\n",
    "b = tf.constant([[2, 4], [6, 8]])\n",
    "\n",
    "# Multiplicar os tensores\n",
    "result = tf.matmul(a, b)\n",
    "\n",
    "print(result.numpy())  # Convertendo para NumPy array para visualização\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.linalg.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.477226\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([1., 2., 3., 4.])\n",
    "\n",
    "# Calcular a norma do tensor\n",
    "norm = tf.linalg.norm(tensor, ord='euclidean')\n",
    "\n",
    "print(norm.numpy())  # Convertendo para NumPy array para visualização\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor\n",
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Transpor o tensor\n",
    "transposed_tensor = tf.transpose(tensor)\n",
    "\n",
    "print(transposed_tensor.numpy())  # Convertendo para NumPy array para visualização\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.linalg.eig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autovalores:\n",
      "[-0.37228122+0.j  5.372281  +0.j]\n",
      "\n",
      "Autovetores:\n",
      "[[-0.8245648 +0.j -0.41597357+0.j]\n",
      " [ 0.56576747+0.j -0.90937674+0.j]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar uma matriz\n",
    "matrix = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# Calcular os autovalores e autovetores\n",
    "eigenvalues, eigenvectors = tf.linalg.eig(matrix)\n",
    "\n",
    "print(\"Autovalores:\")\n",
    "print(eigenvalues.numpy())\n",
    "\n",
    "print(\"\\nAutovetores:\")\n",
    "print(eigenvectors.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers.Dense() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50240 (196.25 KB)\n",
      "Trainable params: 50240 (196.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar uma camada densa com 64 neurônios e ativação ReLU\n",
    "dense_layer = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "\n",
    "# Usar a camada em um modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(784,)),  # Entrada da camada\n",
    "    dense_layer  # Camada densa\n",
    "])\n",
    "\n",
    "# Visualizar o resumo do modelo\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers.Conv2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320 (1.25 KB)\n",
      "Trainable params: 320 (1.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Criar uma camada de convolução com 32 filtros, tamanho de kernel 3x3, ativação ReLU e preenchimento 'same'\n",
    "conv_layer = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')\n",
    "\n",
    "# Usar a camada em um modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),  # Entrada da camada\n",
    "    conv_layer  # Camada de convolução\n",
    "])\n",
    "\n",
    "# Visualizar o resumo do modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.layers.LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24832 (97.00 KB)\n",
      "Trainable params: 24832 (97.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar uma camada LSTM com 64 unidades\n",
    "lstm_layer = tf.keras.layers.LSTM(units=64)\n",
    "\n",
    "# Usar a camada em um modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(10, 32)),  # Entrada da camada (sequência de 10 vetores de tamanho 32)\n",
    "    lstm_layer  # Camada LSTM\n",
    "])\n",
    "\n",
    "# Visualizar o resumo do modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.activations.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2. 0. 4.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor de exemplo\n",
    "x = tf.constant([-1.0, 2.0, -3.0, 4.0])\n",
    "\n",
    "# Aplicar a função ReLU ao tensor\n",
    "output = tf.keras.activations.relu(x)\n",
    "\n",
    "print(output.numpy())  # Convertendo para NumPy array para visualização\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.activations.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26894143 0.5        0.7310586 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor de exemplo\n",
    "x = tf.constant([-1.0, 0.0, 1.0])\n",
    "\n",
    "# Aplicar a função sigmoid ao tensor\n",
    "output = tf.keras.activations.sigmoid(x)\n",
    "\n",
    "print(output.numpy())  # Convertendo para NumPy array para visualização\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.activations.softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09003057 0.24472848 0.66524094]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um tensor de exemplo\n",
    "x = tf.constant([[1.0, 2.0, 3.0]])\n",
    "\n",
    "# Aplicar a função Softmax ao tensor\n",
    "output = tf.keras.activations.softmax(x)\n",
    "\n",
    "print(output.numpy())  # Convertendo para NumPy array para visualização\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.initializers.RandomNormal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50240 (196.25 KB)\n",
      "Trainable params: 50240 (196.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um inicializador com distribuição normal\n",
    "initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
    "\n",
    "# Inicializar uma camada com pesos gerados aleatoriamente\n",
    "layer = tf.keras.layers.Dense(units=64, kernel_initializer=initializer)\n",
    "\n",
    "# Usar a camada em um modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(784,)),  # Entrada da camada\n",
    "    layer  # Camada com pesos inicializados aleatoriamente\n",
    "])\n",
    "\n",
    "# Visualizar o resumo do modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.initializers.GlorotUniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50240 (196.25 KB)\n",
      "Trainable params: 50240 (196.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Criar um inicializador com inicialização de Glorot\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "# Inicializar uma camada com pesos gerados aleatoriamente\n",
    "layer = tf.keras.layers.Dense(units=64, kernel_initializer=initializer)\n",
    "\n",
    "# Usar a camada em um modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(784,)),  # Entrada da camada\n",
    "    layer  # Camada com pesos inicializados aleatoriamente\n",
    "])\n",
    "\n",
    "# Visualizar o resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1642519\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir rótulos verdadeiros e previsões\n",
    "true_labels = tf.constant([1, 0, 1, 0])\n",
    "predictions = tf.constant([0.9, 0.2, 0.8, 0.1])\n",
    "\n",
    "# Calcular a perda usando a entropia cruzada binária\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "loss = loss_function(true_labels, predictions)\n",
    "\n",
    "print(loss.numpy())  # Imprimir a perda calculada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14462154\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir rótulos verdadeiros e previsões\n",
    "true_labels = tf.constant([[0, 1, 0], [1, 0, 0], [0, 0, 1]])  # One-hot encoded labels\n",
    "predictions = tf.constant([[0.1, 0.8, 0.1], [0.9, 0.1, 0.0], [0.0, 0.1, 0.9]])\n",
    "\n",
    "# Calcular a perda usando a entropia cruzada categórica\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "loss = loss_function(true_labels, predictions)\n",
    "\n",
    "print(loss.numpy())  # Imprimir a perda calculada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 3.2554 - accuracy: 0.0000e+00 - val_loss: 2.9996 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.8559 - accuracy: 0.0417 - val_loss: 2.6203 - val_accuracy: 0.3267\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.4884 - accuracy: 0.3250 - val_loss: 2.2802 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1695 - accuracy: 0.3333 - val_loss: 1.9783 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8816 - accuracy: 0.3333 - val_loss: 1.7192 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6399 - accuracy: 0.3667 - val_loss: 1.5070 - val_accuracy: 0.4333\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4429 - accuracy: 0.4583 - val_loss: 1.3417 - val_accuracy: 0.5200\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2954 - accuracy: 0.5167 - val_loss: 1.2156 - val_accuracy: 0.5200\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1806 - accuracy: 0.5167 - val_loss: 1.1218 - val_accuracy: 0.5200\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0970 - accuracy: 0.5000 - val_loss: 1.0518 - val_accuracy: 0.4933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9e88a71090>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar o conjunto de dados Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar um otimizador Adam com a taxa de aprendizado padrão\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Usar o otimizador em um modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.optimizers.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definir um modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar o modelo com o otimizador SGD\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixando seed para reprodutibilidade\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (150, 6)\n"
     ]
    }
   ],
   "source": [
    "connection = sqlite3.connect('databases/iris.sqlite')\n",
    "data = pd.read_sql_query(''' SELECT * FROM IRIS ''', connection)\n",
    "print(\"Shape of data: {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape das features de Entrada: (150, 4)\n",
      "Shape das features de Saida: (150,)\n"
     ]
    }
   ],
   "source": [
    "Y = data['Species']\n",
    "X = data.drop(['Id', 'Species'], axis=1)\n",
    "print(\"Shape das features de Entrada: {}\".format(X.shape))\n",
    "print(\"Shape das features de Saida: {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Input shape\t: (120, 4)\n",
      "Testing Input shape\t: (30, 4)\n",
      "Training Output shape\t: (120, 3)\n",
      "Testing Output shape\t: (30, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_final, test_size=0.2, random_state=seed, stratify=Y_encoded, shuffle=True)\n",
    "\n",
    "print(\"Training Input shape\\t: {}\".format(x_train.shape))\n",
    "print(\"Testing Input shape\\t: {}\".format(x_test.shape))\n",
    "print(\"Training Output shape\\t: {}\".format(y_train.shape))\n",
    "print(\"Testing Output shape\\t: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portanto, nosso formato final do recurso de saída será (150, 3)\n"
     ]
    }
   ],
   "source": [
    "lbl_clf = LabelEncoder()\n",
    "Y_encoded = lbl_clf.fit_transform(Y)\n",
    "\n",
    "# Keras exige que seu recurso de saída tenha valores codificados one-hot.\n",
    "Y_final = tf.keras.utils.to_categorical(Y_encoded)\n",
    "\n",
    "print(\"Portanto, nosso formato final do recurso de saída será {}\".format(Y_final.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_clf = StandardScaler()\n",
    "x_train_new = std_clf.fit_transform(x_train)\n",
    "x_test_new = std_clf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 1ms/step - loss: 1.7146 - accuracy: 0.2667\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.7001 - accuracy: 0.3417\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.7920 - accuracy: 0.2833\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.6710 - accuracy: 0.3333\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5442 - accuracy: 0.3083\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.5777 - accuracy: 0.3083\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.6671 - accuracy: 0.2000\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.5423 - accuracy: 0.2917\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.4942 - accuracy: 0.3000\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.4408 - accuracy: 0.3500\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.4128 - accuracy: 0.3833\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.4263 - accuracy: 0.2917\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.4001 - accuracy: 0.3833\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.3371 - accuracy: 0.4250\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.3117 - accuracy: 0.4917\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2800 - accuracy: 0.4667\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.3210 - accuracy: 0.4333\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2160 - accuracy: 0.5417\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2055 - accuracy: 0.5333\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2984 - accuracy: 0.4167\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2149 - accuracy: 0.4917\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2164 - accuracy: 0.5417\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.2271 - accuracy: 0.5083\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2100 - accuracy: 0.5500\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1762 - accuracy: 0.6083\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1617 - accuracy: 0.5500\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1465 - accuracy: 0.6000\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0579 - accuracy: 0.6167\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1273 - accuracy: 0.5833\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0784 - accuracy: 0.6333\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1242 - accuracy: 0.5667\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0860 - accuracy: 0.6333\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0938 - accuracy: 0.5833\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0002 - accuracy: 0.6833\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9712 - accuracy: 0.6167\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0118 - accuracy: 0.6500\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0384 - accuracy: 0.6250\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9653 - accuracy: 0.6167\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9725 - accuracy: 0.6417\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9794 - accuracy: 0.6000\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8723 - accuracy: 0.7000\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9392 - accuracy: 0.6417\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9148 - accuracy: 0.7083\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9035 - accuracy: 0.6750\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9133 - accuracy: 0.6583\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8881 - accuracy: 0.6583\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.9273 - accuracy: 0.6667\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8461 - accuracy: 0.6833\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8299 - accuracy: 0.7000\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8800 - accuracy: 0.6583\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, input_dim=4, activation=tf.nn.relu, kernel_initializer='he_normal', \n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(7, activation=tf.nn.relu, kernel_initializer='he_normal', \n",
    "                                kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(5, activation=tf.nn.relu, kernel_initializer='he_normal', \n",
    "                                kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "iris_model = model.fit(x_train_new, y_train, epochs=50, batch_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 124ms/step - loss: 0.6236 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6236487627029419, 0.800000011920929]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_new, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 0.6835 - precision_3: 0.6069 - val_loss: 0.5780 - val_precision_3: 0.8077\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5691 - precision_3: 0.8250 - val_loss: 0.4948 - val_precision_3: 0.9630\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4960 - precision_3: 0.8602 - val_loss: 0.4383 - val_precision_3: 0.9032\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4423 - precision_3: 0.8727 - val_loss: 0.3971 - val_precision_3: 0.9062\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4046 - precision_3: 0.8791 - val_loss: 0.3684 - val_precision_3: 0.9062\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3759 - precision_3: 0.8879 - val_loss: 0.3450 - val_precision_3: 0.9355\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3546 - precision_3: 0.8899 - val_loss: 0.3272 - val_precision_3: 0.9355\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3379 - precision_3: 0.8977 - val_loss: 0.3129 - val_precision_3: 0.9375\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3253 - precision_3: 0.8931 - val_loss: 0.3008 - val_precision_3: 0.9375\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3148 - precision_3: 0.8917 - val_loss: 0.2933 - val_precision_3: 0.9375\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3729 - precision_3: 0.9053\n",
      "Test Precision: 0.9052631855010986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Gerar dados de exemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Criar um modelo de classificação binária simples\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar o modelo com a métrica de precisão\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.Precision()])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "test_loss, test_precision = model.evaluate(X_test, y_test)\n",
    "print(f'Test Precision: {test_precision}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.metrics.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 0.6424 - recall_3: 0.9160 - val_loss: 0.5872 - val_recall_3: 0.9167\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5324 - recall_3: 0.8235 - val_loss: 0.4848 - val_recall_3: 0.8333\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4652 - recall_3: 0.7955 - val_loss: 0.4282 - val_recall_3: 0.8333\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4226 - recall_3: 0.8011 - val_loss: 0.3890 - val_recall_3: 0.8333\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3890 - recall_3: 0.8179 - val_loss: 0.3598 - val_recall_3: 0.8611\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3653 - recall_3: 0.8291 - val_loss: 0.3350 - val_recall_3: 0.8611\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3470 - recall_3: 0.8403 - val_loss: 0.3212 - val_recall_3: 0.8333\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3323 - recall_3: 0.8459 - val_loss: 0.3071 - val_recall_3: 0.8333\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3227 - recall_3: 0.8487 - val_loss: 0.2988 - val_recall_3: 0.8333\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3128 - recall_3: 0.8487 - val_loss: 0.2896 - val_recall_3: 0.8333\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3832 - recall_3: 0.7850\n",
      "Test Precision: 0.7850467562675476\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Gerar dados de exemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Criar um modelo de classificação binária simples\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar o modelo com a métrica de precisão\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall()])\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "test_loss, test_precision = model.evaluate(X_test, y_test)\n",
    "print(f'Test Precision: {test_precision}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9047619047619048\n",
      "Recall: 0.95\n",
      "Accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = [[90, 10],\n",
    "               [5, 95]]\n",
    "\n",
    "TN, FP = conf_matrix[0]\n",
    "FN, TP = conf_matrix[1]\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.callbacks.Callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(32, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/25 [>.............................] - ETA: 6s - loss: 0.0000e+00 - accuracy: 0.5000\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55100, saving model to model_checkpoint.h5\n",
      "25/25 [==============================] - 1s 20ms/step - loss: 0.0000e+00 - accuracy: 0.5537 - val_loss: 0.0000e+00 - val_accuracy: 0.5510\n",
      "Epoch 2/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.5000\n",
      "Epoch 2: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5412 - val_loss: 0.0000e+00 - val_accuracy: 0.5270\n",
      "Epoch 3/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n",
      "/home/igor/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5288 - val_loss: 0.0000e+00 - val_accuracy: 0.5080\n",
      "Epoch 4/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.7188\n",
      "Epoch 4: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5150 - val_loss: 0.0000e+00 - val_accuracy: 0.5030\n",
      "Epoch 5/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.4375\n",
      "Epoch 5: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5138 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.6250\n",
      "Epoch 6: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5100 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.3125\n",
      "Epoch 7: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5100 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.5000\n",
      "Epoch 8: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5100 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.5312\n",
      "Epoch 9: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5125 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.5312\n",
      "Epoch 10: val_accuracy did not improve from 0.55100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5113 - val_loss: 0.0000e+00 - val_accuracy: 0.5010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9e089c5240>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Gerar dados de exemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Criar um modelo de classificação binária simples\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Criar o callback ModelCheckpoint para salvar o modelo\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='model_checkpoint.h5', \n",
    "                                                         monitor='val_accuracy', \n",
    "                                                         save_best_only=True,\n",
    "                                                         verbose=1)\n",
    "\n",
    "# Treinar o modelo com o callback ModelCheckpoint\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X, y), callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.callbacks.EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(32, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.5250 - val_loss: 0.0000e+00 - val_accuracy: 0.5120\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5163 - val_loss: 0.0000e+00 - val_accuracy: 0.5040\n",
      "Epoch 3/100\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.5138 - val_loss: 0.0000e+00 - val_accuracy: 0.5020\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5125 - val_loss: 0.0000e+00 - val_accuracy: 0.5010\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5100 - val_loss: 0.0000e+00 - val_accuracy: 0.5010\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5100 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9e08b39930>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Gerar dados de exemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Criar um modelo de classificação binária simples\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Criar o callback EarlyStopping para interromper o treinamento se a precisão de validação não melhorar por 5 épocas\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
    "\n",
    "# Treinar o modelo com o callback EarlyStopping\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X, y), callbacks=[early_stopping_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras.utils.to_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Rótulos de classe (inteiros)\n",
    "y = np.array([0, 1, 2, 1, 0])\n",
    "\n",
    "# Converter para representação one-hot\n",
    "y_one_hot = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "print(y_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding com scikit-learn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categories = [\"maçã\", \"banana\", \"laranja\"]\n",
    "labels = np.array(categories).reshape(-1, 1)\n",
    "\n",
    "# Inicializar o codificador\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Ajustar e transformar os dados\n",
    "one_hot_encoded = encoder.fit_transform(labels)\n",
    "\n",
    "# Converter para array NumPy\n",
    "one_hot_encoded_array = one_hot_encoded.toarray()\n",
    "\n",
    "print(one_hot_encoded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "categories = [\"maçã\", \"banana\", \"laranja\"]\n",
    "encoded = tf.keras.utils.to_categorical(np.arange(len(categories)))\n",
    "\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
